import streamlit as st
import joblib
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassificationa
import numpy as np
import os
import re

# ============================================================
# 1ï¸âƒ£ Load Models (TF-IDF + IndoBERTweet)
# ============================================================
@st.cache_resource

def load_tfidf():
Â  Â  MODEL_PATH = os.path.join(os.path.dirname(__file__), "..", "result", "tf-idf", "intent_classifier_tfidf_lr.pkl")
Â  Â  MODEL_PATH = os.path.abspath(MODEL_PATH)
Â  Â  model = joblib.load(MODEL_PATH)
Â  Â  return model

@st.cache_resource
def load_indobertweet():
Â  Â  model_name = "rilliaa/UChat-IndoBERTweet"Â  # ganti ke repo HF kamu nanti
Â  Â  tokenizer = AutoTokenizer.from_pretrained(model_name)
Â  Â  model = AutoModelForSequenceClassification.from_pretrained(model_name)
Â  Â  return tokenizer, model


# ============================================================
# 2ï¸âƒ£ Rule-based Entity Extraction (Versi Revisi)
# ============================================================

ENTITY_PATTERNS = {
Â  Â  # Tahun Ajaran dan Tahun Akademik
Â  Â  "tahun_ajaran": r"(20\d{2})[/\-â€“](20\d{2})",
Â  Â  "kode_ta": r"TA[_\-]?(20\d{2})",
Â  Â  "tahun_mulai": r"\b(20\d{2})\b(?=.*(mulai|awal))",
Â  Â  "tahun_selesai": r"\b(20\d{2})\b(?=.*(akhir|selesai))",

Â  Â  # Tanggal
Â  Â  "tanggal": r"\b\d{4}[-/]\d{2}[-/]\d{2}\b",

Â  Â  # Nama-nama (guru, murid, wali)
Â  Â  "nama_murid": r"(?<=murid\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",
Â  Â  "nama_murid(anak)": r"(?<=anak\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",
Â  Â  "nama_guru": r"(?<=guru\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",
Â  Â  "nama_guru_pengampu": r"(?<=pengampu\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",
Â  Â  "nama_wali_kelas": r"(?<=wali\s(kelas)\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",
Â  Â  "nama_wali_murid": r"(?<=wali\s(murid)\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",

Â  Â  # Kelas, Mapel, Nilai
Â  Â  "kelas": r"\b(X|XI|XII)[\s\-]?[A-Z]?\b",
Â  Â  "kode_mapel": r"MAPEL[_\-]?[A-Z0-9]+",
Â  Â  "nama_mapel": r"(?<=mata pelajaran\s)([A-Za-z\s]+)",
Â  Â  "mata_pelajaran": r"(?<=pelajaran\s)([A-Za-z\s]+)",
Â  Â  "nilai": r"\b\d{1,3}\b",

Â  Â  # Hari dan jam
Â  Â  "hari": r"\b(Senin|Selasa|Rabu|Kamis|Jumat|Sabtu|Minggu)\b",
Â  Â  "jam_mulai": r"(?<=mulai\s)(\d{2}:\d{2})",
Â  Â  "jam_selesai": r"(?<=selesai\s)(\d{2}:\d{2})",
Â  Â  "jam_ke": r"(?<=jam ke\s)(\d{1,2})",

Â  Â  # Lokasi dan alamat
Â  Â  "lokasi": r"(?<=di\s)([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)",
Â  Â  "alamat": r"(?<=alamat\s)(.*)",

Â  Â  # Identitas
Â  Â  "nip": r"\b\d{18}\b",
Â  Â  "nisn": r"\b\d{10}\b",
Â  Â  "email": r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}",

Â  Â  # Pelanggaran & Prestasi
Â  Â  "nama_pelanggaran": r"(?<=pelanggaran\s)([A-Za-z\s]+)",
Â  Â  "poin_pelanggaran": r"(?<=poin\s(pelanggaran)\s)(\d+)",
Â  Â  "nama_prestasi": r"(?<=prestasi\s)([A-Za-z\s]+)",
Â  Â  "poin_prestasi": r"(?<=poin\s(prestasi)\s)(\d+)",
Â  Â  "keterangan": r"(?<=keterangan\s)([A-Za-z\s]+)",

Â  Â  # Status Kehadiran
Â  Â  "status_kehadiran": r"\b(Hadir|Alpa|Sakit|Izin)\b",
}


def extract_entities(intent: str, text: str):
Â  Â  entities = {}
Â  Â  for name, pattern in ENTITY_PATTERNS.items():
Â  Â  Â  Â  match = re.search(pattern, text, re.IGNORECASE)
Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  entities[name] = match.group(1) if len(match.groups()) == 1 else match.group(0)
Â  Â  return entities


# ============================================================
# 3ï¸âƒ£ Prediction Functions
# ============================================================

def predict_tfidf(text, model):
Â  Â  probs = model.predict_proba([text])[0]
Â  Â  pred = model.classes_[np.argmax(probs)]
Â  Â  probs_percent = {cls: f"{prob*100:.2f}%" for cls, prob in zip(model.classes_, probs)}
Â  Â  return pred, probs_percent


def predict_indobertweet(text, tokenizer, model):
Â  Â  inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
Â  Â  with torch.no_grad():
Â  Â  Â  Â  outputs = model(**inputs)
Â  Â  Â  Â  probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].numpy()
Â  Â  pred_id = np.argmax(probs)
Â  Â  labels = list(model.config.id2label.values())
Â  Â  probs_percent = {label: f"{prob*100:.2f}%" for label, prob in zip(labels, probs)}
Â  Â  return labels[pred_id], probs_percent


# ============================================================
# 4ï¸âƒ£ Confidence Threshold
# ============================================================
CONF_THRESHOLD = 0.35
def is_confident(probs):
Â  Â  return max(probs.values()) > CONF_THRESHOLD * 100


# ============================================================
# 5ï¸âƒ£ Streamlit UI
# ============================================================

st.set_page_config(page_title="UChat NLU MVP", page_icon="ğŸ“", layout="centered")

st.title("ğŸ“ UChat NLU MVP â€” Intent & Entity Demo")

role = st.selectbox("Login sebagai:", ["admin", "teacher", "parent", "student"])
text = st.text_area("Masukkan perintah (Bahasa Indonesia):", height=100)
model_choice = st.radio("Pilih Model:", ["TF-IDF + Logistic Regression", "IndoBERTweet (Fine-tuned)"])

if st.button("Prediksi Intent"):
Â  Â  if not text.strip():
Â  Â  Â  Â  st.warning("âš ï¸ Harap masukkan teks terlebih dahulu.")
Â  Â  else:
Â  Â  Â  Â  if model_choice == "TF-IDF + Logistic Regression":
Â  Â  Â  Â  Â  Â  model = load_tfidf()
Â  Â  Â  Â  Â  Â  pred, probs = predict_tfidf(text, model)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  tokenizer, model = load_indobertweet()
Â  Â  Â  Â  Â  Â  pred, probs = predict_indobertweet(text, tokenizer, model)

Â  Â  Â  Â  # Confidence Check
Â  Â  Â  Â  max_conf = float(max([float(p.strip('%')) for p in probs.values()]))
Â  Â  Â  Â  confident = max_conf >= CONF_THRESHOLD * 100

Â  Â  Â  Â  if confident:
Â  Â  Â  Â  Â  Â  entities = extract_entities(pred, text)
Â  Â  Â  Â  Â  Â  st.success(f"ğŸ¯ Intent: **{pred}**")
Â  Â  Â  Â  Â  Â  st.json({
Â  Â  Â  Â  Â  Â  Â  Â  "confidence (%)": round(max_conf, 2),
Â  Â  Â  Â  Â  Â  Â  Â  "role": role,
Â  Â  Â  Â  Â  Â  Â  Â  "entities": entities
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error("âŒ Sistem tidak yakin dengan prediksi (possible OOD). Permintaan diarahkan ke admin manusia.")
Â  Â  Â  Â  Â  Â  st.json({"predicted_intent": pred, "confidence (%)": round(max_conf, 2)})

st.markdown("---")
st.caption("ğŸ’¡ Dibangun dengan IndoBERTweet & TF-IDF baseline â€” Bahasa Indonesia Intent Classification.")
